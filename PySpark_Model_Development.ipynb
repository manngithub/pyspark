{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark Model of Drug review rate prediction\n",
    "\n",
    "The drug dataset contains patient reviews on different drugs with related conditions and 10-star patient rating reflecting overall patient satisfaction. The goal is to predict the rating score using the review data. A detailed explanation of the data can be found here. We want the model to be able to predict the score for new drug that is not involved in the training data. Here is link to the source data: https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+(Drugs.com)\n",
    "\n",
    "## Model Development Steps on PySpark\n",
    "* [Connect to PySpark](#Connect-to-PySpark)\n",
    "    * Initialize the spark environment\n",
    "    \n",
    "* [Importing Modules](#Importing-Modules)\n",
    "\n",
    "* [Data Ingestion](#Data-Ingestion)\n",
    "    * Connect to HDP1 to collect the training/testing data\n",
    "* [Data Analysis](#Data-Analysis)\n",
    "\n",
    "* [Feature Engineering](#Feature-Engineering)\n",
    "    * Column - 'condition'\n",
    "    * Column - 'date'\n",
    "* [Prepare Modeling Data](#Prepare-Modeling-Data)\n",
    "    * Pipeline\n",
    "\n",
    "* [Model Training](#Model-Training)\n",
    "    * Logistic Regression\n",
    "    * More models (TBD)\n",
    "\n",
    "* [Cross Validation and Model Selection](#Cross-Validation-and-Model-Selection)\n",
    "    * TBD\n",
    "\n",
    "* [Model Testing](#Model-Testing)\n",
    "    * Features calculations on Test Data\n",
    "    * Model Performance on Test Data\n",
    "\n",
    "* [Saving Artifacts](#Saving-Artifacts)\n",
    "\n",
    "### Connect to PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import HiveContext\n",
    "from pyspark.conf import SparkConf\n",
    "spark = SparkSession.builder.config(conf=SparkConf()\\\n",
    "                                    .setMaster(\"yarn\")\\\n",
    "                                    .setAppName(\"Assignment1\")\\\n",
    "                                    .set(\"spark.executor.memory\", '4g')\\\n",
    "                                    .set('spark.executor.cores', '6')).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://domino-run-5e679f854cedfd0008c51d8e:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.0.2.6.5.0-292</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f19b967f490>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoderEstimator\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.sql.functions import datediff, to_date, lit, col, to_timestamp, regexp_extract, udf, lower, concat\n",
    "from pyspark.sql.dataframe import DataFrame\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    "#### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------------------+--------------------+------+------------------+-----------+\n",
      "|    id|   drugname|           condition|              review|rating|             dates|usefulcount|\n",
      "+------+-----------+--------------------+--------------------+------+------------------+-----------+\n",
      "|206461|  Valsartan|Left Ventricular ...|\"It has no side e...|   9.0|      May 20  2012|         27|\n",
      "| 95260|Guanfacine |               ADHD |My son is halfway...|   8.0|   April 27  2010 |        192|\n",
      "| 92703|    Lybrel |      Birth Control |I used to take an...|   5.0|December 14  2009 |         17|\n",
      "|138000|Ortho Evra |      Birth Control |This is my first ...|   8.0| November 3  2015 |         10|\n",
      "+------+-----------+--------------------+--------------------+------+------------------+-----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train = spark.sql('select * from training_path.training_drugreview')\n",
    "df_train = df_train.cache()\n",
    "show_rows = 4\n",
    "df_train.show(show_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- drugname: string (nullable = true)\n",
      " |-- condition: string (nullable = true)\n",
      " |-- review: string (nullable = true)\n",
      " |-- rating: string (nullable = true)\n",
      " |-- dates: string (nullable = true)\n",
      " |-- usefulcount: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+------------+-----------------+------------------+-----------------+\n",
      "|summary|            drugname|   condition|           rating|             dates|      usefulcount|\n",
      "+-------+--------------------+------------+-----------------+------------------+-----------------+\n",
      "|  count|              161297|      161297|           161297|            161297|           161297|\n",
      "|   mean|                null|        null|6.994376832799122|              null|28.00475520313459|\n",
      "| stddev|                null|        null|3.272329209020409|              null|36.40374243129974|\n",
      "|    min|A + D Cracked Ski...|            |              1.0|    April 1  2008 |                0|\n",
      "|    max|             femhrt |zen Shoulde |              9.0|September 9  2017 |               99|\n",
      "+-------+--------------------+------------+-----------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.select('drugname','condition','rating','dates','usefulcount').describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of samples 161297. Review data available from April 1, 2008 to September 9, 2017. usefulcount of reviews ranges from 0 to 99. Next, to work with dates and usefulcount we need to change the datatypes. we will do this in later steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(161297, 7)\n"
     ]
    }
   ],
   "source": [
    "# Shape of the data\n",
    "print(df_train.count(), len(df_train.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|rating|count|\n",
      "+------+-----+\n",
      "|  10.0|50989|\n",
      "|   9.0|27531|\n",
      "|   1.0|21619|\n",
      "|   8.0|18890|\n",
      "|   7.0| 9456|\n",
      "|   5.0| 8013|\n",
      "|   2.0| 6931|\n",
      "|   3.0| 6513|\n",
      "|   6.0| 6343|\n",
      "|   4.0| 5012|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rating Analysis\n",
    "df_train.groupBy('rating').count().orderBy('count', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of samples (rating 10) ~ 10 * Number of samples (rating 4). For multiclass classification model training, we need to address this class imbalance by introducing class weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast 'rating' datatype as Numeric\n",
    "df_train = df_train.withColumn('label', df_train.rating.cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "886"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of distinct conditions\n",
    "df_train.select('condition').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either consider this column as categorical or simple text. We will consider simple text in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|     condition|count|\n",
      "+--------------+-----+\n",
      "|Birth Control |28788|\n",
      "|   Depression | 9069|\n",
      "|         Pain | 6145|\n",
      "|      Anxiety | 5904|\n",
      "+--------------+-----+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Patient Condition\n",
    "#df_train.select('condition').distinct().show(truncate=False)\n",
    "df_train.groupBy('condition').count().orderBy('count', ascending=False).show(show_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of patients are with condition of birth control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+----------------+\n",
      "|           condition|count(condition)|sum(usefulcount)|\n",
      "+--------------------+----------------+----------------+\n",
      "|         Depression |            9069|        458918.0|\n",
      "|            Anxiety |            5904|        300272.0|\n",
      "|      Birth Control |           28788|        224326.0|\n",
      "|               Pain |            6145|        218605.0|\n",
      "|    Bipolar Disorde |            4224|        152603.0|\n",
      "|        Weight Loss |            3609|        139854.0|\n",
      "|            Obesity |            3568|        135174.0|\n",
      "|           Insomnia |            3673|        130801.0|\n",
      "|               ADHD |            3383|        122385.0|\n",
      "|High Blood Pressure |            2321|        105743.0|\n",
      "| Anxiety and Stress |            1663|        105168.0|\n",
      "|               Acne |            5588|         88562.0|\n",
      "|        ibromyalgia |            1791|         84180.0|\n",
      "|   Diabetes  Type 2 |            2554|         73108.0|\n",
      "|      Panic Disorde |            1463|         64908.0|\n",
      "|       Muscle Spasm |            1244|         60307.0|\n",
      "|Generalized Anxie...|            1164|         57551.0|\n",
      "|Erectile Dysfunct...|            1086|         57451.0|\n",
      "|       Chronic Pain |            1455|         55835.0|\n",
      "|     Osteoarthritis |            1239|         49256.0|\n",
      "+--------------------+----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Statistics based on condition\n",
    "# Cast 'usefulcount' datatype as Numeric\n",
    "df_train = df_train.withColumn('usefulcount', df_train.usefulcount.cast('float'))\n",
    "\n",
    "group_condition = df_train.groupBy('condition')\n",
    "\n",
    "group_condition.agg({'condition':'count','usefulcount':'sum',}).orderBy('sum(usefulcount)', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depression, Anxiety, Birth Control, Pain are top conditions from their number of samples and usefulcount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "#### Column - 'condition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression tokenizer\n",
    "regexTokenizer = RegexTokenizer(inputCol=\"condition\", outputCol=\"condition_words\")\n",
    "\n",
    "# bag of words count\n",
    "countVectors = CountVectorizer(inputCol=\"condition_words\", outputCol=\"bof_feature\", vocabSize=df_train.count())\n",
    "\n",
    "# TF-IDF # I might use this feature\n",
    "hashingTF = HashingTF(inputCol=\"condition_words\", outputCol=\"rawFeatures\", numFeatures=10000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"tfidf_feature\", minDocFreq=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column - 'date'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrame object with a transform method\n",
    "def transform(self, f):\n",
    "    return f(self)\n",
    "\n",
    "DataFrame.transform = transform\n",
    "\n",
    "# Convert month column to a numeric string\n",
    "def month_number(x):\n",
    "    if x == 'january':\n",
    "        return '01'\n",
    "    elif x == 'february':\n",
    "        return '02'\n",
    "    elif x == 'march':\n",
    "        return '03'\n",
    "    elif x == 'april':\n",
    "        return '04'\n",
    "    elif x == 'may':\n",
    "        return '05'\n",
    "    elif x == 'june':\n",
    "        return '06'\n",
    "    elif x == 'july':\n",
    "        return '07'\n",
    "    elif x == 'august':\n",
    "        return '08'\n",
    "    elif x == 'september':\n",
    "        return '09'\n",
    "    elif x == 'october':\n",
    "        return '10'\n",
    "    elif x == 'november':\n",
    "        return '11'\n",
    "    else:\n",
    "        return '12'\n",
    "\n",
    "def calculate_date_feature(df):\n",
    "    # Extract day, month and year from dates column\n",
    "    df = df.withColumn('month', regexp_extract(col('dates'), '(.*?)(\\s+)(\\d*)(\\s+)(\\d*)', 1))\n",
    "    df = df.withColumn('day', regexp_extract(col('dates'), '(.*?)(\\s+)(\\d*?)(\\s+)(\\d*)', 3))\n",
    "    df = df.withColumn('year', regexp_extract(col('dates'), '(.*?)(\\s+)(\\d*?)(\\s+)(\\d*)', 5))\n",
    "    \n",
    "    # Convert month column to a numeric string\n",
    "    month_udf = udf(lambda x: month_number(x))\n",
    "    df = df.withColumn('month_number', month_udf(lower(df.month)))\n",
    "    \n",
    "    # new dates column in standard format\n",
    "    df = df.withColumn('dates_temp',concat(df.year,lit('-'),\\\n",
    "                                                        df.month_number,lit('-'),df.day))\n",
    "    df = df.withColumn('dates_converted', df.dates_temp.cast(\"timestamp\"))\n",
    "    \n",
    "    # date feature\n",
    "    df = df.withColumn(\"days_from_review\", \n",
    "              datediff(to_date(lit(\"2020-03-09\")),\n",
    "                       to_date(\"dates_converted\",\"YYYY/MM/dd\")).cast('float'))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.transform(calculate_date_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Imbalance\n",
    "As we saw classes are highly imbalanced so need to introduce class weight for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(rating=u'10.0', count=50989),\n",
       " Row(rating=u'9.0', count=27531),\n",
       " Row(rating=u'1.0', count=21619),\n",
       " Row(rating=u'8.0', count=18890),\n",
       " Row(rating=u'7.0', count=9456),\n",
       " Row(rating=u'5.0', count=8013),\n",
       " Row(rating=u'2.0', count=6931),\n",
       " Row(rating=u'3.0', count=6513),\n",
       " Row(rating=u'6.0', count=6343),\n",
       " Row(rating=u'4.0', count=5012)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupBy('rating').count().orderBy('count', ascending=False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>count</th>\n",
       "      <th>class_weight_temp</th>\n",
       "      <th>class_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>27531</td>\n",
       "      <td>5</td>\n",
       "      <td>0.030488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>8013</td>\n",
       "      <td>20</td>\n",
       "      <td>0.121951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9456</td>\n",
       "      <td>17</td>\n",
       "      <td>0.103659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>6931</td>\n",
       "      <td>23</td>\n",
       "      <td>0.140244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>6513</td>\n",
       "      <td>24</td>\n",
       "      <td>0.146341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.0</td>\n",
       "      <td>50989</td>\n",
       "      <td>3</td>\n",
       "      <td>0.018293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>21619</td>\n",
       "      <td>7</td>\n",
       "      <td>0.042683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.0</td>\n",
       "      <td>6343</td>\n",
       "      <td>25</td>\n",
       "      <td>0.152439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.0</td>\n",
       "      <td>18890</td>\n",
       "      <td>8</td>\n",
       "      <td>0.048780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5012</td>\n",
       "      <td>32</td>\n",
       "      <td>0.195122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  count  class_weight_temp  class_weight\n",
       "0    9.0  27531                  5      0.030488\n",
       "1    5.0   8013                 20      0.121951\n",
       "2    7.0   9456                 17      0.103659\n",
       "3    2.0   6931                 23      0.140244\n",
       "4    3.0   6513                 24      0.146341\n",
       "5   10.0  50989                  3      0.018293\n",
       "6    1.0  21619                  7      0.042683\n",
       "7    6.0   6343                 25      0.152439\n",
       "8    8.0  18890                  8      0.048780\n",
       "9    4.0   5012                 32      0.195122"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating weights in pandas dataframe\n",
    "rating_count = df_train.groupBy('label').count().select('label','count').toPandas()\n",
    "# class weights\n",
    "count_sum = rating_count['count'].sum()\n",
    "rating_count['class_weight_temp'] = rating_count['count'].apply(lambda x: count_sum/x)\n",
    "# normalize the weights\n",
    "class_weight_temp_sum = rating_count['class_weight_temp'].sum()\n",
    "rating_count['class_weight'] = rating_count['class_weight_temp'].apply(lambda x: float(x)/class_weight_temp_sum)\n",
    "rating_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_weights1(x):\n",
    "    if x == 10:\n",
    "        return 0.0188\n",
    "    elif x == 9:\n",
    "        return 0.034\n",
    "    elif x == 1:\n",
    "        return 0.044\n",
    "    elif x == 8:\n",
    "        return 0.05\n",
    "    elif x == 7:\n",
    "        return 0.1\n",
    "    elif x == 5:\n",
    "        return 0.119\n",
    "    elif x == 2:\n",
    "        return 0.138\n",
    "    elif x == 3:\n",
    "        return 0.147\n",
    "    elif x == 6:\n",
    "        return 0.151\n",
    "    elif x == 4:\n",
    "        return 0.191\n",
    "\n",
    "# this did not work\n",
    "def class_weights(x):\n",
    "    return rating_count.loc[rating_count['label'] == x,'class_weight'].values[0]\n",
    "\n",
    "    \n",
    "classWeight_udf = udf(lambda x: class_weights1(x))\n",
    "df_train = df_train.withColumn('classWeight', classWeight_udf(df_train.label).cast('float'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------------------+--------------------+------+------------------+-----------+-----+--------+---+----+------------+----------+-------------------+----------------+-----------+\n",
      "|    id|   drugname|           condition|              review|rating|             dates|usefulcount|label|   month|day|year|month_number|dates_temp|    dates_converted|days_from_review|classWeight|\n",
      "+------+-----------+--------------------+--------------------+------+------------------+-----------+-----+--------+---+----+------------+----------+-------------------+----------------+-----------+\n",
      "|206461|  Valsartan|Left Ventricular ...|\"It has no side e...|   9.0|      May 20  2012|       27.0|  9.0|     May| 20|2012|          05|2012-05-20|2012-05-20 00:00:00|          2850.0|      0.034|\n",
      "| 95260|Guanfacine |               ADHD |My son is halfway...|   8.0|   April 27  2010 |      192.0|  8.0|   April| 27|2010|          04|2010-04-27|2010-04-27 00:00:00|          3604.0|       0.05|\n",
      "| 92703|    Lybrel |      Birth Control |I used to take an...|   5.0|December 14  2009 |       17.0|  5.0|December| 14|2009|          12|2009-12-14|2009-12-14 00:00:00|          3738.0|      0.119|\n",
      "|138000|Ortho Evra |      Birth Control |This is my first ...|   8.0| November 3  2015 |       10.0|  8.0|November|  3|2015|          11| 2015-11-3|2015-11-03 00:00:00|          1588.0|       0.05|\n",
      "+------+-----------+--------------------+--------------------+------+------------------+-----------+-----+--------+---+----+------------+----------+-------------------+----------------+-----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show(show_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Modeling Data\n",
    "#### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+--------------------+--------------------+------+------------------+-----------+-----+--------+---+----+------------+----------+-------------------+----------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    id|   drugname|           condition|              review|rating|             dates|usefulcount|label|   month|day|year|month_number|dates_temp|    dates_converted|days_from_review|classWeight|     condition_words|         bof_feature|         rawFeatures|       tfidf_feature|            features|\n",
      "+------+-----------+--------------------+--------------------+------+------------------+-----------+-----+--------+---+----+------------+----------+-------------------+----------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|206461|  Valsartan|Left Ventricular ...|\"It has no side e...|   9.0|      May 20  2012|       27.0|  9.0|     May| 20|2012|          05|2012-05-20|2012-05-20 00:00:00|          2850.0|      0.034|[left, ventricula...|(1096,[53,316,469...|(10000,[1662,9745...|(10000,[1662,9745...|(10002,[1662,9745...|\n",
      "| 95260|Guanfacine |               ADHD |My son is halfway...|   8.0|   April 27  2010 |      192.0|  8.0|   April| 27|2010|          04|2010-04-27|2010-04-27 00:00:00|          3604.0|       0.05|              [adhd]|   (1096,[13],[1.0])|(10000,[3615],[1.0])|(10000,[3615],[3....|(10002,[3615,1000...|\n",
      "| 92703|    Lybrel |      Birth Control |I used to take an...|   5.0|December 14  2009 |       17.0|  5.0|December| 14|2009|          12|2009-12-14|2009-12-14 00:00:00|          3738.0|      0.119|    [birth, control]|(1096,[0,1],[1.0,...|(10000,[2371,3874...|(10000,[2371,3874...|(10002,[2371,3874...|\n",
      "|138000|Ortho Evra |      Birth Control |This is my first ...|   8.0| November 3  2015 |       10.0|  8.0|November|  3|2015|          11| 2015-11-3|2015-11-03 00:00:00|          1588.0|       0.05|    [birth, control]|(1096,[0,1],[1.0,...|(10000,[2371,3874...|(10000,[2371,3874...|(10002,[2371,3874...|\n",
      "+------+-----------+--------------------+--------------------+------+------------------+-----------+-----+--------+---+----+------------+----------+-------------------+----------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# assemble data for modeling\n",
    "#vec_assembler = VectorAssembler(inputCols=[\"bof_feature\", \"rawFeatures\", \"tfidf_feature\", \"days_from_review\", \"usefulcount\"], outputCol=\"features\")\n",
    "vec_assembler = VectorAssembler(inputCols=[\"tfidf_feature\", \"days_from_review\", \"usefulcount\"], outputCol=\"features\")\n",
    "\n",
    "# pipeline of different stages\n",
    "pipeline = Pipeline(stages=[regexTokenizer, countVectors, hashingTF, idf, vec_assembler])\n",
    "pipelineModel = pipeline.fit(df_train)\n",
    "training_data = pipelineModel.transform(df_train)#.select('condition','condition_words','bof_feature','rawFeatures','tfidf_feature').show()\n",
    "training_data.show(show_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_and_evaluation(model_string, model_object, training_data):\n",
    "    print('{}:'.format(model_string))\n",
    "    # model training\n",
    "    model = model_object.fit(training_data)\n",
    "    \n",
    "    trainingSummary = model.summary\n",
    "    print('Training data accuracy: ' + str(trainingSummary.accuracy))\n",
    "    \n",
    "    training_predictions = model.transform(training_data)\n",
    "    \n",
    "    # Another way to check multiclass prediction accuracy\n",
    "    # evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol = \"prediction\")\n",
    "    # print('Training data accuracy: ', evaluator.evaluate(training_predictions, {evaluator.metricName: \"accuracy\"}))\n",
    "    \n",
    "    pred_result = training_predictions.select('rating','prediction','probability').toPandas()\n",
    "\n",
    "    y_actu = pd.Series(pred_result['rating'], name='Actual')\n",
    "    y_pred = pd.Series(pred_result['prediction'], name='Predicted')\n",
    "    df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "\n",
    "    print(\"Confusion matrix:\")\n",
    "    \n",
    "    return model, df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "Training data accuracy: 0.343019398997\n",
      "Confusion matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "      <th>3.0</th>\n",
       "      <th>4.0</th>\n",
       "      <th>5.0</th>\n",
       "      <th>6.0</th>\n",
       "      <th>7.0</th>\n",
       "      <th>8.0</th>\n",
       "      <th>9.0</th>\n",
       "      <th>10.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>8884</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>107</td>\n",
       "      <td>248</td>\n",
       "      <td>12359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>4972</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>181</td>\n",
       "      <td>587</td>\n",
       "      <td>45186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>2298</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>60</td>\n",
       "      <td>100</td>\n",
       "      <td>4449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1954</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>62</td>\n",
       "      <td>135</td>\n",
       "      <td>4323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1439</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>126</td>\n",
       "      <td>3385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>2182</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>214</td>\n",
       "      <td>5490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>1408</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>76</td>\n",
       "      <td>188</td>\n",
       "      <td>4641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>1727</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>99</td>\n",
       "      <td>300</td>\n",
       "      <td>7284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>2799</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>311</td>\n",
       "      <td>492</td>\n",
       "      <td>15252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>3086</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>185</td>\n",
       "      <td>830</td>\n",
       "      <td>23394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  1.0   2.0   3.0   4.0   5.0   6.0   7.0   8.0   9.0    10.0\n",
       "Actual                                                                \n",
       "1.0        8884     3     1     4     7     1     5   107   248  12359\n",
       "10.0       4972     4     8    11    18     6    16   181   587  45186\n",
       "2.0        2298    14     3     1     3     1     2    60   100   4449\n",
       "3.0        1954     3    22     1     5     0     8    62   135   4323\n",
       "4.0        1439     1     3    12     3     2     5    36   126   3385\n",
       "5.0        2182     3     3     2    31     2     1    85   214   5490\n",
       "6.0        1408     2     3     0     9    12     4    76   188   4641\n",
       "7.0        1727     1     3     2     9     5    26    99   300   7284\n",
       "8.0        2799     2     6     3    13     4     8   311   492  15252\n",
       "9.0        3086     2     8     9    11     1     5   185   830  23394"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=50) # weightCol=\"classWeights\"\n",
    "# weight class was tried but did not help.\n",
    "model_lr, confusion_mat_lr = training_and_evaluation('Logistic Regression', lr, training_data)\n",
    "confusion_mat_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label\", numTrees = 50, maxDepth = 4)\n",
    "model_rf, confusion_mat_rf = training_and_evaluation('Random Forest', rf, training_data)\n",
    "confusion_mat_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(featuresCol = 'features', labelCol = 'label', maxDepth = 3)\n",
    "model_dt, confusion_mat_dt = training_and_evaluation('Decision Tree', dt, training_data)\n",
    "confusion_mat_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes()\n",
    "model_nb, confusion_mat_nb = training_and_evaluation('Naive Bayes', nb, training_data)\n",
    "confusion_mat_nb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation and Model Selection\n",
    "optimal parameters not found"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lr = LogisticRegression(featuresCol = 'features', labelCol = 'label', maxIter=50)\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(lr.regParam, [0.01, 0.5, 2.0]) # regularization parameter\n",
    "             .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) # Elastic Net Parameter (Ridge = 0)\n",
    "#            .addGrid(model.maxIter, [10, 20, 50]) #Number of iterations\n",
    "#            .addGrid(idf.numFeatures, [10, 100, 1000]) # Number of features\n",
    "             .build())\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol = \"prediction\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create 5-fold CrossValidator\n",
    "cv = CrossValidator(estimator=lr, \\\n",
    "                    estimatorParamMaps=paramGrid, \\\n",
    "                    evaluator=evaluator, \\\n",
    "                    numFolds=5)\n",
    "cvModel = cv.fit(training_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CV results\n",
    "cv_predictions = cvModel.transform(training_data)\n",
    "# Evaluate best model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\")\n",
    "evaluator.evaluate(cv_predictions, {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------------------+--------------------+------------------+-----------+\n",
      "| id|   drugname|           condition|              review|             dates|usefulcount|\n",
      "+---+-----------+--------------------+--------------------+------------------+-----------+\n",
      "|  0|Mirtazapine|          Depression|\"I&#039;ve tried ...| February 28  2012|         22|\n",
      "|  1| Mesalamine|Crohn's Disease  ...|My son has Crohn&...|      May 17  2009|         17|\n",
      "|  2|    Bactrim|Urinary Tract Inf...|Quick reduction o...|September 29  2017|          3|\n",
      "|  3|   Contrave|         Weight Loss|Contrave combines...|     March 5  2017|         35|\n",
      "+---+-----------+--------------------+--------------------+------------------+-----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test = spark.sql('select * from test_path.test_drug_review')\n",
    "df_test = df_test.cache()\n",
    "df_test.show(show_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features calculations on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.transform(calculate_date_feature)\n",
    "df_test = df_test.withColumn('usefulcount', df_test.usefulcount.cast('float'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_lr\n",
    "testing_data = pipelineModel.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+--------------------+--------------------+------------------+-----------+---------+---+----+------------+----------+-------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "| id|   drugname|           condition|              review|             dates|usefulcount|    month|day|year|month_number|dates_temp|    dates_converted|days_from_review|     condition_words|         bof_feature|         rawFeatures|       tfidf_feature|            features|       rawPrediction|         probability|prediction|\n",
      "+---+-----------+--------------------+--------------------+------------------+-----------+---------+---+----+------------+----------+-------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|  0|Mirtazapine|          Depression|\"I&#039;ve tried ...| February 28  2012|       22.0| February| 28|2012|          02|2012-02-28|2012-02-28 00:00:00|          2932.0|        [depression]|    (1096,[4],[1.0])|(10000,[3119],[1.0])|(10000,[3119],[2....|(10002,[3119,1000...|[-8.5862846414690...|[6.72528860111964...|      10.0|\n",
      "|  1| Mesalamine|Crohn's Disease  ...|My son has Crohn&...|      May 17  2009|       17.0|      May| 17|2009|          05|2009-05-17|2009-05-17 00:00:00|          3949.0|[crohn's, disease...|(1096,[54,60,123]...|(10000,[3117,8975...|(10000,[3117,8975...|(10002,[3117,8975...|[-8.6066534801744...|[4.97161664648780...|      10.0|\n",
      "|  2|    Bactrim|Urinary Tract Inf...|Quick reduction o...|September 29  2017|        3.0|September| 29|2017|          09|2017-09-29|2017-09-29 00:00:00|           892.0|[urinary, tract, ...|(1096,[6,42,43],[...|(10000,[3167,5538...|(10000,[3167,5538...|(10002,[3167,5538...|[-8.5735648136954...|[5.57522891885175...|       1.0|\n",
      "|  3|   Contrave|         Weight Loss|Contrave combines...|     March 5  2017|       35.0|    March|  5|2017|          03| 2017-03-5|2017-03-05 00:00:00|          1100.0|      [weight, loss]|(1096,[10,11],[1....|(10000,[4589,5329...|(10000,[4589,5329...|(10002,[4589,5329...|[-8.5696360986998...|[4.41628355302318...|      10.0|\n",
      "+---+-----------+--------------------+--------------------+------------------+-----------+---------+---+----+------------+----------+-------------------+----------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.transform(testing_data)\n",
    "test_predictions.show(show_rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
